{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"SYDNzta9zm2y","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eegYaNB0ztwI","colab_type":"code","outputId":"bca8850d-a2ed-4bb1-cd5f-810d6caf8728","executionInfo":{"status":"ok","timestamp":1560527805072,"user_tz":-480,"elapsed":4049,"user":{"displayName":"Zihao Chu","photoUrl":"https://lh3.googleusercontent.com/-saqR8rzOH3Y/AAAAAAAAAAI/AAAAAAAAAAc/4tFycMz-njM/s64/photo.jpg","userId":"03782091127250714574"}},"colab":{"base_uri":"https://localhost:8080/","height":140}},"source":["%cd /content/drive/My\\ Drive/NLP/Medical\n","!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/NLP/Medical\n","data\t\t\tNN.ipynb\t\t word2vec300.npy\n","data_reader_general.py\tpos2vec300.npy\t\t word2vec300_simple.npy\n","data_reader_new.py\tpos2vec500.npy\t\t word2vec500.npy\n","data_reader.py\t\t__pycache__\t\t word2vec500_simple.npy\n","data_reader_simple.py\ttf_glove.py\n","distribution.txt\ttrain_word_vector.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iZFQHPxP83nf","colab_type":"code","outputId":"e7057c81-eedf-4cc7-ab51-d347a6df2421","executionInfo":{"status":"ok","timestamp":1560527339939,"user_tz":-480,"elapsed":4440,"user":{"displayName":"Zihao Chu","photoUrl":"https://lh3.googleusercontent.com/-saqR8rzOH3Y/AAAAAAAAAAI/AAAAAAAAAAc/4tFycMz-njM/s64/photo.jpg","userId":"03782091127250714574"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!pip install numpy==1.16.1"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: numpy==1.16.1 in /usr/local/lib/python3.6/dist-packages (1.16.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t5rkT1Us0DGt","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","from torchvision import datasets, transforms\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.optim import lr_scheduler\n","import torchvision\n","import numpy as np\n","import random\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yZfqKjdT8vae","colab_type":"code","outputId":"8261fd3a-eaa9-476f-bf50-a5269ae2074d","executionInfo":{"status":"ok","timestamp":1560527814845,"user_tz":-480,"elapsed":8665,"user":{"displayName":"Zihao Chu","photoUrl":"https://lh3.googleusercontent.com/-saqR8rzOH3Y/AAAAAAAAAAI/AAAAAAAAAAc/4tFycMz-njM/s64/photo.jpg","userId":"03782091127250714574"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import data_reader_general\n","SemData = data_reader_general.read_data_sets('data', padding=True, shuffle=True, noZero=True, simple=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["###################################################################################################"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z8oBAUdI8w3u","colab_type":"code","outputId":"83a6a42c-aab9-4b23-b90c-34640d1dbbde","executionInfo":{"status":"ok","timestamp":1560527814846,"user_tz":-480,"elapsed":4932,"user":{"displayName":"Zihao Chu","photoUrl":"https://lh3.googleusercontent.com/-saqR8rzOH3Y/AAAAAAAAAAI/AAAAAAAAAAc/4tFycMz-njM/s64/photo.jpg","userId":"03782091127250714574"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["print(len(SemData.train.sentences))\n","print(len(SemData.validation.sentences))\n","print(len(SemData.test.sentences))\n","print(len(SemData.weight))\n","print(SemData.embedding_matrix.shape)\n","print(SemData.postag_matrix.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["13218\n","4405\n","4405\n","14\n","(36515, 500)\n","(44, 500)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6qrchG6B9E_u","colab_type":"code","colab":{}},"source":["class Params():\n","    def __init__(self):\n","        # ALL\n","        self.n_inputs = 500 # 300\n","        self.n_class = 14 # 15 if noZero==False\n","        self.batch_size = 128\n","        self.n_train = 10000\n","        self.n_display = 500\n","        self.half_test_size = 2200\n","        # RNN & LSTM\n","        self.n_hidden = 128\n","        # CNN\n","        self.max_length = 110\n","\n","params = Params()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"On1hsJojdO9R","colab_type":"code","colab":{}},"source":["class CNN1(nn.Module):\n","    def __init__(self):\n","        super(CNN1, self).__init__()\n","        self.n_inputs = params.n_inputs\n","        self.n_class = params.n_class\n","        self.batch_size = params.batch_size\n","        self.max_length = params.max_length\n","        \n","        # self.embedding_matrix = nn.Parameter(torch.tensor(SemData.embedding_matrix))\n","        self.embedding_matrix = torch.tensor(SemData.embedding_matrix).cuda()\n","        # self.postag_matrix = nn.Parameter(torch.tensor(SemData.postag_matrix))\n","        self.postag_matrix = torch.tensor(SemData.postag_matrix).cuda()\n","        self.conv = nn.Conv2d(1, 128, (5, 300), stride=1, padding=(2, 0))\n","        self.relu = nn.ReLU()\n","        self.fc = nn.Linear(128, self.n_class)\n","        \n","    def forward(self, sentences, postags):\n","        sentences = nn.functional.embedding(torch.tensor(sentences).cuda(), self.embedding_matrix)\n","        #postags = nn.functional.embedding(torch.tensor(postags).cuda(), self.postag_matrix)\n","        #sentences = torch.tensor(sentences + postags).cuda()\n","        x = torch.unsqueeze(sentences, 1).float()\n","        y_conv = self.conv(x)\n","        y_relu = self.relu(y_conv)\n","        y_max, _ = torch.max(y_relu, 2)\n","        y_flatten = torch.reshape(y_max, [-1, 128])\n","        output = self.fc(y_flatten)\n","        return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bzk6T82i9Htu","colab_type":"code","colab":{}},"source":["class CNN2(nn.Module):\n","    def __init__(self):\n","        super(CNN2, self).__init__()\n","        self.n_inputs = params.n_inputs\n","        self.n_class = params.n_class\n","        self.batch_size = params.batch_size\n","        self.max_length = params.max_length\n","        \n","        # self.embedding_matrix = nn.Parameter(torch.tensor(SemData.embedding_matrix))\n","        self.embedding_matrix = torch.tensor(SemData.embedding_matrix).cuda()\n","        # self.postag_matrix = nn.Parameter(torch.tensor(SemData.postag_matrix))\n","        self.postag_matrix = torch.tensor(SemData.postag_matrix).cuda()\n","        self.relu = nn.ReLU()\n","        self.conv1 = nn.Conv2d(1, 32, (5, 500), 1, (2, 0))\n","        self.pool1 = nn.MaxPool2d((5, 1), stride=(2, 1), padding=(2, 0))\n","        self.conv2 = nn.Conv2d(32, 128, (5, 1), 1, (2, 0))\n","        self.fc1 = nn.Linear(128, self.n_class)\n","        \n","    def forward(self, sentences, postags):\n","        sentences = nn.functional.embedding(torch.tensor(sentences).cuda(), self.embedding_matrix)\n","        postags = nn.functional.embedding(torch.tensor(postags).cuda(), self.postag_matrix)\n","        sentences = torch.tensor(sentences + postags).cuda()\n","        x = torch.unsqueeze(sentences, 1).float()\n","        y_conv1 = self.conv1(x)\n","        y_relu1 = self.relu(y_conv1)\n","        y_pool1 = self.pool1(y_relu1)\n","        y_conv2 = self.conv2(y_pool1)\n","        y_relu2 = self.relu(y_conv2)\n","        y_max, _ = torch.max(y_relu2, 2)\n","        y_flatten = torch.reshape(y_max, [-1, 128])\n","        y_flatten = torch.nn.functional.dropout(y_flatten, 0.3).float()\n","        output = self.fc1(y_flatten)\n","        return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"99dBjJjopVd9","colab_type":"code","colab":{}},"source":["class RNN(nn.Module):\n","    def __init__(self):\n","        super(RNN, self).__init__()\n","        self.n_inputs = params.n_inputs\n","        self.n_hidden = params.n_hidden\n","        self.n_class = params.n_class\n","        self.batch_size = params.batch_size\n","        \n","        # self.embedding_matrix = nn.Parameter(torch.tensor(SemData.embedding_matrix))\n","        self.embedding_matrix = torch.tensor(SemData.embedding_matrix).cuda()\n","        # self.postag_matrix = torch.tensor(SemData.postag_matrix).cuda()\n","        self.postag_matrix = torch.tensor(SemData.postag_matrix).cuda()\n","        self.rnn = nn.RNN(self.n_inputs, self.n_hidden, bidirectional=False)\n","        self.fc = nn.Linear(self.n_hidden, self.n_class)\n","        self.h0 = torch.randn(1, 1, self.n_hidden).cuda()\n","    \n","    def forward(self, sentences, postags):\n","        output = torch.tensor([]).cuda()\n","        for i in range(len(sentences)):\n","            sentence = nn.functional.embedding(torch.tensor(sentences[i]).cuda(), self.embedding_matrix)\n","            sentence = sentence.unsqueeze(1).float()\n","            # sentence = torch.unsqueeze(sentence, 0)\n","            # sentence = sentence.permute(1, 0, 2).float()\n","            _, h = self.rnn(sentence, self.h0)\n","            h = torch.nn.functional.dropout(h[0], 0.5).float()\n","            out = self.fc(h)\n","            output = torch.cat((output, out), 0)\n","        return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cobe7-smHa84","colab_type":"code","colab":{}},"source":["class LSTM(nn.Module):\n","    def __init__(self):\n","        super(LSTM, self).__init__()\n","        self.n_inputs = params.n_inputs\n","        self.n_hidden = params.n_hidden\n","        self.n_class = params.n_class\n","        self.batch_size = params.batch_size\n","        \n","        self.embedding_matrix = nn.Parameter(torch.tensor(SemData.embedding_matrix))\n","        # self.embedding_matrix = torch.tensor(SemData.embedding_matrix).cuda()\n","        self.postag_matrix = torch.tensor(SemData.postag_matrix).cuda()\n","        # self.postag_matrix = torch.tensor(SemData.postag_matrix).cuda()\n","        self.lstm = nn.LSTM(self.n_inputs, self.n_hidden, bidirectional=False)\n","        self.fc = nn.Linear(self.n_hidden, self.n_class)\n","        self.h0 = torch.randn(1, 1, self.n_hidden).cuda()\n","        self.c0 = torch.randn(1, 1, self.n_hidden).cuda()\n","    \n","    def forward(self, sentences, postags):\n","        output = torch.tensor([]).cuda()\n","        for i in range(len(sentences)):\n","            sentence = nn.functional.embedding(torch.tensor(sentences[i]).cuda(), self.embedding_matrix)\n","            sentence = sentence.unsqueeze(1).float()\n","            # sentence = torch.unsqueeze(sentence, 0)\n","            # sentence = sentence.permute(1, 0, 2).float()\n","            _, (h, _) = self.lstm(sentence, (self.h0, self.c0))\n","            h = torch.nn.functional.dropout(h[0], 0.5).float()\n","            out = self.fc(h)\n","            output = torch.cat((output, out), 0)\n","        return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3QwC9t339q8Y","colab_type":"code","colab":{}},"source":["class BiLSTM(nn.Module):\n","    def __init__(self):\n","        super(BiLSTM, self).__init__()\n","        self.n_inputs = params.n_inputs\n","        self.n_hidden = params.n_hidden\n","        self.n_class = params.n_class\n","        self.batch_size = params.batch_size\n","        \n","        # self.embedding_matrix = nn.Parameter(torch.tensor(SemData.embedding_matrix))\n","        self.embedding_matrix = torch.tensor(SemData.embedding_matrix).cuda()\n","        # self.postag_matrix = nn.Parameter(torch.tensor(SemData.postag_matrix))\n","        self.postag_matrix = torch.tensor(SemData.postag_matrix).cuda()\n","        self.lstm = nn.LSTM(self.n_inputs, self.n_hidden, bidirectional=True)\n","        self.fc = nn.Linear(self.n_hidden, self.n_class)\n","        self.h0 = torch.randn(2, 1, self.n_hidden).cuda()\n","        self.c0 = torch.randn(2, 1, self.n_hidden).cuda()\n","    \n","    def forward(self, sentences, postags):\n","        output = torch.tensor([]).cuda()\n","        for i in range(len(sentences)):\n","            sentence = nn.functional.embedding(torch.tensor(sentences[i]).cuda(), self.embedding_matrix)\n","            postag = nn.functional.embedding(torch.tensor(postags[i]).cuda(), self.postag_matrix)\n","            sentence = (torch.tensor(sentence) + torch.tensor(postag))\n","            sentence = sentence.unsqueeze(1).float()\n","            h_fb, (_, _) = self.lstm(sentence, (self.h0, self.c0))\n","            h, _ = torch.max(h_fb[:, :, 0:self.n_hidden]+h_fb[:, :, self.n_hidden:], 0)\n","            h = torch.nn.functional.dropout(h, 0.5).float()\n","            out = self.fc(h)\n","            output = torch.cat((output, out), 0)\n","        return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aTpvBXP46Mkk","colab_type":"code","colab":{}},"source":["model = CNN2()\n","model = model.cuda()\n","criterion = nn.CrossEntropyLoss(weight=torch.tensor(SemData.weight, dtype=torch.float).cuda())\n","optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.01)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2mNzbVMf9uzo","colab_type":"code","colab":{}},"source":["def cond_mat(mat, preds, labels):\n","    for i in range(len(labels)):\n","        mat[preds[i], labels[i]] += 1\n","    return mat"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O1gCDXF89wDo","colab_type":"code","colab":{}},"source":["def train():\n","    start = time.clock()\n","    for step in range(params.n_train):\n","        train_sentences, train_postags, train_labels = SemData.train.next_batch(params.batch_size)\n","        train_labels = torch.tensor(train_labels).cuda()\n","        optimizer.zero_grad()\n","        train_output = model(train_sentences, train_postags)\n","        _, train_golden = torch.max(train_labels, 1)\n","        train_loss = criterion(train_output, train_golden)\n","        train_loss.backward()\n","        optimizer.step()\n","        if step%params.n_display == 0 or step == params.n_train-1 :\n","            print('#')\n","            print(\"<step: %d>\" % (step))\n","            train_mat = torch.zeros(14, 14).cuda() # 15 if onZero==False\n","            _, train_preds = torch.max(train_output, 1)\n","            train_mat = cond_mat(train_mat, train_preds, train_golden)\n","            train_accuracy = torch.trace(train_mat) / params.batch_size\n","            print(\"train_accuracy: %2.4f %%, local_loss: %.8f\" % (train_accuracy*100, train_loss.item()))\n","            \n","            validation_mat = torch.zeros(14, 14).cuda() # 15 if onZero==False\n","            validation_loss = 0.\n","            for _ in range(2):\n","                validation_sentences, validation_postags, validation_labels = SemData.validation.next_batch(params.half_test_size)\n","                validation_labels = torch.tensor(validation_labels).cuda()\n","                validation_output = model(validation_sentences, validation_postags)\n","                _, validation_preds = torch.max(validation_output, 1)\n","                _, validation_golden = torch.max(validation_labels, 1)\n","                validation_mat = cond_mat(validation_mat, validation_preds, validation_golden)\n","                validation_loss += criterion(validation_output, validation_golden).item() / 2\n","            validation_accuracy = torch.trace(validation_mat) / (2 * params.half_test_size)\n","            # f1 score (macro)\n","            TP = (torch.tensor([validation_mat[i, i] for i in range(14)]) + 1e-5).cuda()\n","            FP = torch.sum(validation_mat, 1) - TP\n","            FN = torch.sum(validation_mat, 0) - TP\n","            P = TP / (TP + FP)\n","            R = TP / (TP + FN)\n","            validation_f1 = torch.mean(2 / (1/P+1/R))\n","            print(\"validation_accuracy:  %2.4f %%, total_loss: %.8f, f1_score: %2.2f\" % (validation_accuracy*100, validation_loss, validation_f1*100))\n","        if step%10 == 0:\n","            print('#', end='')\n","    print(\"------------------------------------\")\n","    print(\"training time: \", time.clock()-start, \" s\")\n","    test_mat = torch.zeros(14, 14).cuda() # 15 if onZero==False\n","    test_loss = 0.\n","    for _ in range(2):\n","        test_sentences, test_postags, test_labels = SemData.test.next_batch(params.half_test_size)\n","        test_labels = torch.tensor(test_labels).cuda()\n","        test_output = model(test_sentences, test_postags)\n","        _, test_preds = torch.max(test_output, 1)\n","        _, test_golden = torch.max(test_labels, 1)\n","        test_mat = cond_mat(test_mat, test_preds, test_golden)\n","        test_loss += criterion(test_output, test_golden).item() / 2\n","    test_accuracy = torch.trace(test_mat) / (2 * params.half_test_size)\n","    # f1 score (macro)\n","    TP = (torch.tensor([test_mat[i, i] for i in range(14)]) + 1e-5).cuda()\n","    FP = torch.sum(test_mat, 1) - TP\n","    FN = torch.sum(test_mat, 0) - TP\n","    P = TP / (TP + FP)\n","    R = TP / (TP + FN)\n","    test_f1 = torch.mean(2 / (1/P+1/R))\n","    print(\"test_accuracy:  %2.4f %%, total_loss: %.8f, f1_score: %2.2f\" % (test_accuracy*100, test_loss, test_f1*100))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_R3xDa89-m1X","colab_type":"code","outputId":"3b2536a3-6979-47a9-b1c6-6aafa06f1f75","executionInfo":{"status":"ok","timestamp":1560317391503,"user_tz":-480,"elapsed":3597586,"user":{"displayName":"Zihao Chu","photoUrl":"https://lh3.googleusercontent.com/-saqR8rzOH3Y/AAAAAAAAAAI/AAAAAAAAAAc/4tFycMz-njM/s64/photo.jpg","userId":"03782091127250714574"}},"colab":{"base_uri":"https://localhost:8080/","height":1128}},"source":["train() # CNN2"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["#\n","<step: 0>\n","train_accuracy: 9.3750 %, local_loss: 2.72360158\n","validation_accuracy:  10.3864 %, total_loss: 2.64607215, f1_score: 4.60\n","###################################################\n","<step: 500>\n","train_accuracy: 81.2500 %, local_loss: 0.33697829\n","validation_accuracy:  79.0455 %, total_loss: 0.86834222, f1_score: 62.11\n","###################################################\n","<step: 1000>\n","train_accuracy: 81.2500 %, local_loss: 0.35704994\n","validation_accuracy:  79.7273 %, total_loss: 0.78856674, f1_score: 62.33\n","###################################################\n","<step: 1500>\n","train_accuracy: 85.1562 %, local_loss: 0.19550689\n","validation_accuracy:  83.5455 %, total_loss: 1.07066968, f1_score: 66.59\n","###################################################\n","<step: 2000>\n","train_accuracy: 86.7188 %, local_loss: 0.23347276\n","validation_accuracy:  83.3864 %, total_loss: 0.87905720, f1_score: 68.07\n","###################################################\n","<step: 2500>\n","train_accuracy: 92.1875 %, local_loss: 0.18983062\n","validation_accuracy:  84.7500 %, total_loss: 0.96151158, f1_score: 68.80\n","###################################################\n","<step: 3000>\n","train_accuracy: 87.5000 %, local_loss: 0.25601688\n","validation_accuracy:  82.6136 %, total_loss: 1.15348390, f1_score: 69.58\n","###################################################\n","<step: 3500>\n","train_accuracy: 87.5000 %, local_loss: 0.24130332\n","validation_accuracy:  84.4318 %, total_loss: 1.06221423, f1_score: 67.48\n","###################################################\n","<step: 4000>\n","train_accuracy: 83.5938 %, local_loss: 0.31407729\n","validation_accuracy:  82.8409 %, total_loss: 0.97443670, f1_score: 67.12\n","###################################################\n","<step: 4500>\n","train_accuracy: 90.6250 %, local_loss: 0.12691343\n","validation_accuracy:  87.4318 %, total_loss: 1.02572152, f1_score: 72.33\n","###################################################\n","<step: 5000>\n","train_accuracy: 92.1875 %, local_loss: 0.12518357\n","validation_accuracy:  88.1591 %, total_loss: 1.12915677, f1_score: 71.21\n","###################################################\n","<step: 5500>\n","train_accuracy: 81.2500 %, local_loss: 0.31819189\n","validation_accuracy:  78.7273 %, total_loss: 0.90682009, f1_score: 63.57\n","###################################################\n","<step: 6000>\n","train_accuracy: 93.7500 %, local_loss: 0.11323523\n","validation_accuracy:  86.8409 %, total_loss: 0.86801216, f1_score: 70.22\n","###################################################\n","<step: 6500>\n","train_accuracy: 91.4062 %, local_loss: 0.15767406\n","validation_accuracy:  85.6136 %, total_loss: 0.81424910, f1_score: 68.71\n","###################################################\n","<step: 7000>\n","train_accuracy: 95.3125 %, local_loss: 0.11029941\n","validation_accuracy:  86.7273 %, total_loss: 0.98892453, f1_score: 72.74\n","##############################################"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RR_yTlRs1drq","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}