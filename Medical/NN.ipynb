{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"NN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","execution_count":null,"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"metadata":{"id":"SYDNzta9zm2y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1589439700914,"user_tz":-480,"elapsed":1214,"user":{"displayName":"Zihao Chu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCsjNMtSarSx44yVllSyMOdqSsWCwYptDiSywd=s64","userId":"03782091127250714574"}},"outputId":"58440628-2614-49bb-a47a-b7d65b666d3d"}},{"cell_type":"code","execution_count":null,"source":["%cd /content/drive/My\\ Drive/NLP/Medical\n","!ls"],"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/NLP/Medical\n","data\t\t\tNN.ipynb\t\t word2vec300.npy\n","data_reader_general.py\tpos2vec300.npy\t\t word2vec300_simple.npy\n","data_reader_new.py\tpos2vec500.npy\t\t word2vec500.npy\n","data_reader.py\t\t__pycache__\t\t word2vec500_simple.npy\n","data_reader_simple.py\ttf_glove.py\n","distribution.txt\ttrain_word_vector.ipynb\n"]}],"metadata":{"id":"eegYaNB0ztwI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":134},"executionInfo":{"status":"ok","timestamp":1589439705640,"user_tz":-480,"elapsed":5120,"user":{"displayName":"Zihao Chu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCsjNMtSarSx44yVllSyMOdqSsWCwYptDiSywd=s64","userId":"03782091127250714574"}},"outputId":"6d19fc05-e0d2-4a30-f3c3-1c73da6932f1"}},{"cell_type":"code","execution_count":null,"source":["!pip install numpy==1.16.1"],"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy==1.16.1 in /usr/local/lib/python3.6/dist-packages (1.16.1)\n"]}],"metadata":{"id":"iZFQHPxP83nf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1589438461592,"user_tz":-480,"elapsed":6910,"user":{"displayName":"Zihao Chu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCsjNMtSarSx44yVllSyMOdqSsWCwYptDiSywd=s64","userId":"03782091127250714574"}},"outputId":"775b42f6-59a2-4a1d-90ca-554be7a9af3c"}},{"cell_type":"code","execution_count":null,"source":["import torch\r\n","import torch.nn as nn\r\n","from torchvision import datasets, transforms\r\n","import torch.optim as optim\r\n","from torch.autograd import Variable\r\n","from torch.optim import lr_scheduler\r\n","import torchvision\r\n","import numpy as np\r\n","import random\r\n","import time"],"outputs":[],"metadata":{"id":"t5rkT1Us0DGt","colab_type":"code","colab":{}}},{"cell_type":"code","execution_count":null,"source":["import data_reader\r\n","SemData = data_reader.read_data_sets('data', padding=True, shuffle=True, noZero=True, simple=True)"],"outputs":[{"output_type":"stream","name":"stdout","text":["###################################################################################################"]}],"metadata":{"id":"yZfqKjdT8vae","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1589439712211,"user_tz":-480,"elapsed":7265,"user":{"displayName":"Zihao Chu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCsjNMtSarSx44yVllSyMOdqSsWCwYptDiSywd=s64","userId":"03782091127250714574"}},"outputId":"9666c6e5-51eb-4d83-e4e7-fa8ab7128ca8"}},{"cell_type":"code","execution_count":null,"source":["print(len(SemData.train.sentences))\r\n","print(len(SemData.validation.sentences))\r\n","print(len(SemData.test.sentences))\r\n","print(len(SemData.weight))\r\n","print(SemData.embedding_matrix.shape)\r\n","print(SemData.postag_matrix.shape)"],"outputs":[{"output_type":"stream","name":"stdout","text":["13218\n","4405\n","4405\n","14\n","(13480, 500)\n","(44, 500)\n"]}],"metadata":{"id":"z8oBAUdI8w3u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":118},"executionInfo":{"status":"ok","timestamp":1589439712213,"user_tz":-480,"elapsed":4675,"user":{"displayName":"Zihao Chu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCsjNMtSarSx44yVllSyMOdqSsWCwYptDiSywd=s64","userId":"03782091127250714574"}},"outputId":"3421c4e0-9c1d-4d87-a357-996fb2ef102e"}},{"cell_type":"code","execution_count":null,"source":["class Params():\r\n","    def __init__(self):\r\n","        # ALL\r\n","        self.n_inputs = 500 # 300\r\n","        self.n_class = 14 # 15 if noZero==False\r\n","        self.batch_size = 128\r\n","        self.n_train = 10000\r\n","        self.n_display = 500\r\n","        self.half_test_size = 2200\r\n","        # RNN & LSTM\r\n","        self.n_hidden = 128\r\n","        # CNN\r\n","        self.max_length = 110\r\n","\r\n","params = Params()"],"outputs":[],"metadata":{"id":"6qrchG6B9E_u","colab_type":"code","colab":{}}},{"cell_type":"code","execution_count":null,"source":["class CNN1(nn.Module):\n","    def __init__(self):\n","        super(CNN1, self).__init__()\n","        self.n_inputs = params.n_inputs\n","        self.n_class = params.n_class\n","        self.batch_size = params.batch_size\n","        self.max_length = params.max_length\n","        \n","        # self.embedding_matrix = nn.Parameter(torch.tensor(SemData.embedding_matrix))\n","        self.embedding_matrix = torch.tensor(SemData.embedding_matrix).cuda()\n","        # self.postag_matrix = nn.Parameter(torch.tensor(SemData.postag_matrix))\n","        self.postag_matrix = torch.tensor(SemData.postag_matrix).cuda()\n","        self.conv = nn.Conv2d(1, 128, (5, 300), stride=1, padding=(2, 0))\n","        self.relu = nn.ReLU()\n","        self.fc = nn.Linear(128, self.n_class)\n","        \n","    def forward(self, sentences, postags):\n","        sentences = nn.functional.embedding(torch.tensor(sentences).cuda(), self.embedding_matrix)\n","        #postags = nn.functional.embedding(torch.tensor(postags).cuda(), self.postag_matrix)\n","        #sentences = torch.tensor(sentences + postags).cuda()\n","        x = torch.unsqueeze(sentences, 1).float()\n","        y_conv = self.conv(x)\n","        y_relu = self.relu(y_conv)\n","        y_max, _ = torch.max(y_relu, 2)\n","        y_flatten = torch.reshape(y_max, [-1, 128])\n","        output = self.fc(y_flatten)\n","        return output"],"outputs":[],"metadata":{"id":"On1hsJojdO9R","colab_type":"code","colab":{}}},{"cell_type":"code","execution_count":null,"source":["class CNN2(nn.Module):\n","    def __init__(self):\n","        super(CNN2, self).__init__()\n","        self.n_inputs = params.n_inputs\n","        self.n_class = params.n_class\n","        self.batch_size = params.batch_size\n","        self.max_length = params.max_length\n","        \n","        self.embedding_matrix = nn.Parameter(torch.tensor(SemData.embedding_matrix))\n","        # self.embedding_matrix = torch.tensor(SemData.embedding_matrix).cuda()\n","        self.postag_matrix = nn.Parameter(torch.tensor(SemData.postag_matrix))\n","        # self.postag_matrix = torch.tensor(SemData.postag_matrix).cuda()\n","        self.relu = nn.ReLU()\n","        self.conv1 = nn.Conv2d(1, 32, (5, 500), 1, (2, 0))\n","        self.pool1 = nn.MaxPool2d((5, 1), stride=(2, 1), padding=(2, 0))\n","        self.conv2 = nn.Conv2d(32, 128, (5, 1), 1, (2, 0))\n","        self.fc1 = nn.Linear(128, self.n_class)\n","        \n","    def forward(self, sentences, postags):\n","        sentences = nn.functional.embedding(torch.tensor(sentences).cuda(), self.embedding_matrix)\n","        postags = nn.functional.embedding(torch.tensor(postags).cuda(), self.postag_matrix)\n","        sentences = torch.tensor(sentences + postags).cuda()\n","        x = torch.unsqueeze(sentences, 1).float()\n","        y_conv1 = self.conv1(x)\n","        y_relu1 = self.relu(y_conv1)\n","        y_pool1 = self.pool1(y_relu1)\n","        y_conv2 = self.conv2(y_pool1)\n","        y_relu2 = self.relu(y_conv2)\n","        y_max, _ = torch.max(y_relu2, 2)\n","        y_flatten = torch.reshape(y_max, [-1, 128])\n","        y_flatten = torch.nn.functional.dropout(y_flatten, 0.3).float()\n","        output = self.fc1(y_flatten)\n","        return output"],"outputs":[],"metadata":{"id":"Bzk6T82i9Htu","colab_type":"code","colab":{}}},{"cell_type":"code","execution_count":null,"source":["class RNN(nn.Module):\n","    def __init__(self):\n","        super(RNN, self).__init__()\n","        self.n_inputs = params.n_inputs\n","        self.n_hidden = params.n_hidden\n","        self.n_class = params.n_class\n","        self.batch_size = params.batch_size\n","        \n","        # self.embedding_matrix = nn.Parameter(torch.tensor(SemData.embedding_matrix))\n","        self.embedding_matrix = torch.tensor(SemData.embedding_matrix).cuda()\n","        # self.postag_matrix = torch.tensor(SemData.postag_matrix).cuda()\n","        self.postag_matrix = torch.tensor(SemData.postag_matrix).cuda()\n","        self.rnn = nn.RNN(self.n_inputs, self.n_hidden, bidirectional=False)\n","        self.fc = nn.Linear(self.n_hidden, self.n_class)\n","        self.h0 = torch.randn(1, 1, self.n_hidden).cuda()\n","    \n","    def forward(self, sentences, postags):\n","        output = torch.tensor([]).cuda()\n","        for i in range(len(sentences)):\n","            sentence = nn.functional.embedding(torch.tensor(sentences[i]).cuda(), self.embedding_matrix)\n","            sentence = sentence.unsqueeze(1).float()\n","            # sentence = torch.unsqueeze(sentence, 0)\n","            # sentence = sentence.permute(1, 0, 2).float()\n","            _, h = self.rnn(sentence, self.h0)\n","            h = torch.nn.functional.dropout(h[0], 0.5).float()\n","            out = self.fc(h)\n","            output = torch.cat((output, out), 0)\n","        return output"],"outputs":[],"metadata":{"id":"99dBjJjopVd9","colab_type":"code","colab":{}}},{"cell_type":"code","execution_count":null,"source":["class LSTM(nn.Module):\n","    def __init__(self):\n","        super(LSTM, self).__init__()\n","        self.n_inputs = params.n_inputs\n","        self.n_hidden = params.n_hidden\n","        self.n_class = params.n_class\n","        self.batch_size = params.batch_size\n","        \n","        self.embedding_matrix = nn.Parameter(torch.tensor(SemData.embedding_matrix))\n","        # self.embedding_matrix = torch.tensor(SemData.embedding_matrix).cuda()\n","        self.postag_matrix = torch.tensor(SemData.postag_matrix).cuda()\n","        # self.postag_matrix = torch.tensor(SemData.postag_matrix).cuda()\n","        self.lstm = nn.LSTM(self.n_inputs, self.n_hidden, bidirectional=False)\n","        self.fc = nn.Linear(self.n_hidden, self.n_class)\n","        self.h0 = torch.randn(1, 1, self.n_hidden).cuda()\n","        self.c0 = torch.randn(1, 1, self.n_hidden).cuda()\n","    \n","    def forward(self, sentences, postags):\n","        output = torch.tensor([]).cuda()\n","        for i in range(len(sentences)):\n","            sentence = nn.functional.embedding(torch.tensor(sentences[i]).cuda(), self.embedding_matrix)\n","            sentence = sentence.unsqueeze(1).float()\n","            # sentence = torch.unsqueeze(sentence, 0)\n","            # sentence = sentence.permute(1, 0, 2).float()\n","            _, (h, _) = self.lstm(sentence, (self.h0, self.c0))\n","            h = torch.nn.functional.dropout(h[0], 0.5).float()\n","            out = self.fc(h)\n","            output = torch.cat((output, out), 0)\n","        return output"],"outputs":[],"metadata":{"id":"Cobe7-smHa84","colab_type":"code","colab":{}}},{"cell_type":"code","execution_count":null,"source":["class BiLSTM(nn.Module):\n","    def __init__(self):\n","        super(BiLSTM, self).__init__()\n","        self.n_inputs = params.n_inputs\n","        self.n_hidden = params.n_hidden\n","        self.n_class = params.n_class\n","        self.batch_size = params.batch_size\n","        \n","        # self.embedding_matrix = nn.Parameter(torch.tensor(SemData.embedding_matrix))\n","        self.embedding_matrix = torch.tensor(SemData.embedding_matrix).cuda()\n","        # self.postag_matrix = nn.Parameter(torch.tensor(SemData.postag_matrix))\n","        self.postag_matrix = torch.tensor(SemData.postag_matrix).cuda()\n","        self.lstm = nn.LSTM(self.n_inputs, self.n_hidden, bidirectional=True)\n","        self.fc = nn.Linear(self.n_hidden, self.n_class)\n","        self.h0 = torch.randn(2, 1, self.n_hidden).cuda()\n","        self.c0 = torch.randn(2, 1, self.n_hidden).cuda()\n","    \n","    def forward(self, sentences, postags):\n","        output = torch.tensor([]).cuda()\n","        for i in range(len(sentences)):\n","            sentence = nn.functional.embedding(torch.tensor(sentences[i]).cuda(), self.embedding_matrix)\n","            postag = nn.functional.embedding(torch.tensor(postags[i]).cuda(), self.postag_matrix)\n","            sentence = (torch.tensor(sentence) + torch.tensor(postag))\n","            sentence = sentence.unsqueeze(1).float()\n","            h_fb, (_, _) = self.lstm(sentence, (self.h0, self.c0))\n","            h, _ = torch.max(h_fb[:, :, 0:self.n_hidden]+h_fb[:, :, self.n_hidden:], 0)\n","            h = torch.nn.functional.dropout(h, 0.5).float()\n","            out = self.fc(h)\n","            output = torch.cat((output, out), 0)\n","        return output"],"outputs":[],"metadata":{"id":"3QwC9t339q8Y","colab_type":"code","colab":{}}},{"cell_type":"code","execution_count":null,"source":["model = CNN2()\n","model = model.cuda()\n","criterion = nn.CrossEntropyLoss(weight=torch.tensor(SemData.weight, dtype=torch.float).cuda())\n","optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.01)"],"outputs":[],"metadata":{"id":"aTpvBXP46Mkk","colab_type":"code","colab":{}}},{"cell_type":"code","execution_count":null,"source":["def cond_mat(mat, preds, labels):\n","    for i in range(len(labels)):\n","        mat[preds[i], labels[i]] += 1\n","    return mat"],"outputs":[],"metadata":{"id":"2mNzbVMf9uzo","colab_type":"code","colab":{}}},{"cell_type":"code","execution_count":null,"source":["def train():\n","    start = time.clock()\n","    for step in range(params.n_train):\n","        train_sentences, train_postags, train_labels = SemData.train.next_batch(params.batch_size)\n","        train_labels = torch.tensor(train_labels).cuda()\n","        optimizer.zero_grad()\n","        train_output = model(train_sentences, train_postags)\n","        _, train_golden = torch.max(train_labels, 1)\n","        train_loss = criterion(train_output, train_golden)\n","        train_loss.backward()\n","        optimizer.step()\n","        if step%params.n_display == 0 or step == params.n_train-1 :\n","            print('#')\n","            print(\"<step: %d>\" % (step))\n","            train_mat = torch.zeros(14, 14).cuda() # 15 if onZero==False\n","            _, train_preds = torch.max(train_output, 1)\n","            train_mat = cond_mat(train_mat, train_preds, train_golden)\n","            train_accuracy = torch.trace(train_mat) / params.batch_size\n","            print(\"train_accuracy: %2.4f %%, local_loss: %.8f\" % (train_accuracy*100, train_loss.item()))\n","            \n","            validation_mat = torch.zeros(14, 14).cuda() # 15 if onZero==False\n","            validation_loss = 0.\n","            for _ in range(2):\n","                validation_sentences, validation_postags, validation_labels = SemData.validation.next_batch(params.half_test_size)\n","                validation_labels = torch.tensor(validation_labels).cuda()\n","                validation_output = model(validation_sentences, validation_postags)\n","                _, validation_preds = torch.max(validation_output, 1)\n","                _, validation_golden = torch.max(validation_labels, 1)\n","                validation_mat = cond_mat(validation_mat, validation_preds, validation_golden)\n","                validation_loss += criterion(validation_output, validation_golden).item() / 2\n","            validation_accuracy = torch.trace(validation_mat) / (2 * params.half_test_size)\n","            # f1 score (macro)\n","            TP = (torch.tensor([validation_mat[i, i] for i in range(14)]) + 1e-5).cuda()\n","            FP = torch.sum(validation_mat, 1) - TP\n","            FN = torch.sum(validation_mat, 0) - TP\n","            P = TP / (TP + FP)\n","            R = TP / (TP + FN)\n","            validation_f1 = torch.mean(2 / (1/P+1/R))\n","            print(\"validation_accuracy:  %2.4f %%, total_loss: %.8f, f1_score: %2.2f\" % (validation_accuracy*100, validation_loss, validation_f1*100))\n","        if step%10 == 0:\n","            print('#', end='')\n","    print(\"------------------------------------\")\n","    print(\"training time: \", time.clock()-start, \" s\")\n","    test_mat = torch.zeros(14, 14).cuda() # 15 if onZero==False\n","    test_loss = 0.\n","    for _ in range(2):\n","        test_sentences, test_postags, test_labels = SemData.test.next_batch(params.half_test_size)\n","        test_labels = torch.tensor(test_labels).cuda()\n","        test_output = model(test_sentences, test_postags)\n","        _, test_preds = torch.max(test_output, 1)\n","        _, test_golden = torch.max(test_labels, 1)\n","        test_mat = cond_mat(test_mat, test_preds, test_golden)\n","        test_loss += criterion(test_output, test_golden).item() / 2\n","    test_accuracy = torch.trace(test_mat) / (2 * params.half_test_size)\n","    # f1 score (macro)\n","    TP = (torch.tensor([test_mat[i, i] for i in range(14)]) + 1e-5).cuda()\n","    FP = torch.sum(test_mat, 1) - TP\n","    FN = torch.sum(test_mat, 0) - TP\n","    P = TP / (TP + FP)\n","    R = TP / (TP + FN)\n","    test_f1 = torch.mean(2 / (1/P+1/R))\n","    print(\"test_accuracy:  %2.4f %%, total_loss: %.8f, f1_score: %2.2f\" % (test_accuracy*100, test_loss, test_f1*100))"],"outputs":[],"metadata":{"id":"O1gCDXF89wDo","colab_type":"code","colab":{}}},{"cell_type":"code","execution_count":null,"source":["train() # CNN2"],"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]},{"output_type":"stream","name":"stdout","text":["#\n","<step: 0>\n","train_accuracy: 2.3438 %, local_loss: 2.71135283\n","validation_accuracy:  5.3864 %, total_loss: 2.66232932, f1_score: 2.48\n","###################################################\n","<step: 500>\n","train_accuracy: 82.8125 %, local_loss: 0.42521039\n","validation_accuracy:  80.4091 %, total_loss: 0.78896004, f1_score: 63.55\n","###################################################\n","<step: 1000>\n","train_accuracy: 79.6875 %, local_loss: 0.26099491\n","validation_accuracy:  75.0000 %, total_loss: 0.61359832, f1_score: 62.73\n","###################################################\n","<step: 1500>\n","train_accuracy: 83.5938 %, local_loss: 0.31087881\n","validation_accuracy:  85.3864 %, total_loss: 0.80219343, f1_score: 68.34\n","###################################################\n","<step: 2000>\n","train_accuracy: 85.9375 %, local_loss: 0.34707311\n","validation_accuracy:  84.5682 %, total_loss: 0.75580728, f1_score: 67.71\n","###################################################\n","<step: 2500>\n","train_accuracy: 92.1875 %, local_loss: 0.21292025\n","validation_accuracy:  86.2955 %, total_loss: 0.94213378, f1_score: 69.46\n","###################################################\n","<step: 3000>\n","train_accuracy: 88.2812 %, local_loss: 0.26997200\n","validation_accuracy:  86.3864 %, total_loss: 0.81971085, f1_score: 68.74\n","###################################################\n","<step: 3500>\n","train_accuracy: 85.9375 %, local_loss: 0.28014284\n","validation_accuracy:  84.6591 %, total_loss: 0.99531308, f1_score: 67.88\n","###################################################\n","<step: 4000>\n","train_accuracy: 84.3750 %, local_loss: 0.34892508\n","validation_accuracy:  83.6591 %, total_loss: 0.98876697, f1_score: 68.63\n","###################################################\n","<step: 4500>\n","train_accuracy: 85.1562 %, local_loss: 0.21664616\n","validation_accuracy:  84.2273 %, total_loss: 0.79028231, f1_score: 66.89\n","###################################################\n","<step: 5000>\n","train_accuracy: 92.1875 %, local_loss: 0.16507842\n","validation_accuracy:  85.5000 %, total_loss: 0.83832455, f1_score: 70.54\n","###################################################\n","<step: 5500>\n","train_accuracy: 91.4062 %, local_loss: 0.16975997\n","validation_accuracy:  86.9091 %, total_loss: 0.86810005, f1_score: 70.34\n","###################################################\n","<step: 6000>\n","train_accuracy: 89.8438 %, local_loss: 0.17868450\n","validation_accuracy:  84.9091 %, total_loss: 0.82753503, f1_score: 67.26\n","###################################################\n","<step: 6500>\n","train_accuracy: 87.5000 %, local_loss: 0.14572026\n","validation_accuracy:  83.8409 %, total_loss: 0.79794103, f1_score: 67.13\n","###################################################\n","<step: 7000>\n","train_accuracy: 95.3125 %, local_loss: 0.14180806\n","validation_accuracy:  82.9545 %, total_loss: 0.91459659, f1_score: 67.32\n","###################################################\n","<step: 7500>\n","train_accuracy: 85.1562 %, local_loss: 0.16214091\n","validation_accuracy:  85.0227 %, total_loss: 0.81282160, f1_score: 69.11\n","###################################################\n","<step: 8000>\n","train_accuracy: 89.0625 %, local_loss: 0.24572206\n","validation_accuracy:  83.0909 %, total_loss: 0.69741085, f1_score: 66.73\n","###################################################\n","<step: 8500>\n","train_accuracy: 86.7188 %, local_loss: 0.21354929\n","validation_accuracy:  85.2727 %, total_loss: 0.80834079, f1_score: 70.82\n","###################################################\n","<step: 9000>\n","train_accuracy: 90.6250 %, local_loss: 0.20245026\n","validation_accuracy:  86.5000 %, total_loss: 0.86714235, f1_score: 68.82\n","###################################################\n","<step: 9500>\n","train_accuracy: 91.4062 %, local_loss: 0.17349946\n","validation_accuracy:  87.9091 %, total_loss: 0.98679885, f1_score: 74.60\n","###################################################\n","<step: 9999>\n","train_accuracy: 82.0312 %, local_loss: 0.31261384\n","validation_accuracy:  83.2273 %, total_loss: 0.74841791, f1_score: 65.75\n","------------------------------------\n","training time:  133.06635  s\n","test_accuracy:  84.0682 %, total_loss: 0.75865456, f1_score: 67.53\n"]}],"metadata":{"id":"_R3xDa89-m1X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1589439863508,"user_tz":-480,"elapsed":139350,"user":{"displayName":"Zihao Chu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCsjNMtSarSx44yVllSyMOdqSsWCwYptDiSywd=s64","userId":"03782091127250714574"}},"outputId":"4a31d565-2ad3-4209-ea68-c8c6f1b1eb22"}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{"id":"RR_yTlRs1drq","colab_type":"code","colab":{}}}]}