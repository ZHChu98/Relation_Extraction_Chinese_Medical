{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_FILE.txt existed\n",
      "TEST_FILE.txt existed\n"
     ]
    }
   ],
   "source": [
    "import data_reader\n",
    "SemData = data_reader.read_data_sets(\"data\", padding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000,)\n",
      "(2717,)\n"
     ]
    }
   ],
   "source": [
    "print(SemData.train.sentences.shape)\n",
    "print(SemData.test.sentences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params():\n",
    "    def __init__(self):\n",
    "        self.n_inputs = 300\n",
    "        self.n_hidden = 150\n",
    "        self.n_class = 19\n",
    "        self.batch_size = 128\n",
    "        self.n_train = 2000\n",
    "        self.n_display = 100\n",
    "        self.test_size = 2717\n",
    "\n",
    "params = Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.n_inputs = params.n_inputs\n",
    "        self.n_hidden = params.n_hidden\n",
    "        self.n_class = params.n_class\n",
    "        self.batch_size = params.batch_size\n",
    "        self.rnn = nn.RNN(self.n_inputs, self.n_hidden)\n",
    "        self.lstm = nn.LSTM(self.n_inputs, self.n_hidden)\n",
    "        self.fc = nn.Linear(self.n_hidden, self.n_class)\n",
    "        self.h0 = torch.randn(1, 1, self.n_hidden).cuda()\n",
    "        self.c0 = torch.randn(1, 1, self.n_hidden).cuda()\n",
    "    \n",
    "    def forward(self, sentences):\n",
    "        for i in range(len(sentences)):\n",
    "            sen_len = sentences[i].shape[0]\n",
    "            sentence = sentences[i].reshape(1, sen_len, self.n_inputs)\n",
    "            sentence = torch.tensor(sentence.transpose(1, 0, 2)).cuda()\n",
    "            # _, h = self.rnn(sentence, self.h0)\n",
    "            _, (h, _) = self.lstm(sentence, (self.h0, self.c0))\n",
    "            h = torch.nn.functional.dropout(h, 0.5)\n",
    "            out = self.fc(h[0])\n",
    "            if i==0:\n",
    "                output = out\n",
    "            else:\n",
    "                output = torch.cat([output, out])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN()\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    start = time.clock()\n",
    "    test_sentences = SemData.test.sentences\n",
    "    test_labels = torch.tensor(SemData.test.labels).cuda()\n",
    "    for step in range(params.n_train):\n",
    "        sentences, labels = SemData.train.next_batch(params.batch_size)\n",
    "        labels = torch.tensor(labels).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(sentences)\n",
    "        _, train_golden = torch.max(labels, 1)\n",
    "        loss = criterion(logits, train_golden)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % params.n_display == 0:\n",
    "            _, preds = torch.max(logits, 1)\n",
    "            train_accuracy = torch.sum(preds == train_golden).item() / params.batch_size\n",
    "            \n",
    "            test_logits = model(test_sentences)\n",
    "            _, test_preds = torch.max(test_logits, 1)\n",
    "            _, test_golden = torch.max(test_labels, 1)\n",
    "            test_loss = criterion(test_logits, test_golden)\n",
    "            test_accuracy = torch.sum(test_preds == test_golden).item() / params.test_size\n",
    "            print(\"<step: %d>\" % (step))\n",
    "            print(\"train_accuracy: %.4g %% local_loss: %.8g\" % (train_accuracy*100, loss.item()))\n",
    "            print(\"test_accuracy: %.4g %% total_loss: %.8g\" % (test_accuracy*100, test_loss.item()))\n",
    "    print(\"------------------------------------\")\n",
    "    print(\"training time: \", time.clock()-start, \" s\")\n",
    "    test_logits = model(test_sentences)\n",
    "    _, test_preds = torch.max(test_logits, 1)\n",
    "    _, test_golden = torch.max(test_labels, 1)\n",
    "    test_loss = criterion(test_logits, test_golden)\n",
    "    test_accuracy = torch.sum(test_preds == test_golden).item() / params.test_size\n",
    "    print(\"test_accuracy: %.4g %% total_loss: %.8g\" % (test_accuracy*100, test_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<step: 0>\n",
      "train_accuracy: 9.375 % local_loss: 2.9261742\n",
      "test_accuracy: 11.19 % total_loss: 2.8763506\n",
      "<step: 100>\n",
      "train_accuracy: 16.41 % local_loss: 2.6115258\n",
      "test_accuracy: 16.08 % total_loss: 2.6712329\n",
      "<step: 200>\n",
      "train_accuracy: 21.88 % local_loss: 2.4935794\n",
      "test_accuracy: 17.63 % total_loss: 2.6652174\n",
      "<step: 300>\n",
      "train_accuracy: 37.5 % local_loss: 2.205471\n",
      "test_accuracy: 20.21 % total_loss: 2.5219367\n",
      "<step: 400>\n",
      "train_accuracy: 47.66 % local_loss: 1.9282322\n",
      "test_accuracy: 20.57 % total_loss: 2.5854838\n",
      "<step: 500>\n",
      "train_accuracy: 42.19 % local_loss: 1.9235288\n",
      "test_accuracy: 21.31 % total_loss: 2.6803162\n",
      "<step: 600>\n",
      "train_accuracy: 42.19 % local_loss: 1.781953\n",
      "test_accuracy: 21.05 % total_loss: 2.7049806\n",
      "<step: 700>\n",
      "train_accuracy: 46.09 % local_loss: 1.7690461\n",
      "test_accuracy: 20.76 % total_loss: 2.9145789\n",
      "<step: 800>\n",
      "train_accuracy: 53.91 % local_loss: 1.5275216\n",
      "test_accuracy: 21.9 % total_loss: 2.860441\n",
      "<step: 900>\n",
      "train_accuracy: 62.5 % local_loss: 1.302924\n",
      "test_accuracy: 20.1 % total_loss: 3.169349\n",
      "<step: 1000>\n",
      "train_accuracy: 65.62 % local_loss: 1.2177753\n",
      "test_accuracy: 20.72 % total_loss: 3.2309327\n",
      "<step: 1100>\n",
      "train_accuracy: 63.28 % local_loss: 1.1796749\n",
      "test_accuracy: 20.28 % total_loss: 3.3711212\n",
      "<step: 1200>\n",
      "train_accuracy: 74.22 % local_loss: 0.84749031\n",
      "test_accuracy: 21.53 % total_loss: 3.5321949\n",
      "<step: 1300>\n",
      "train_accuracy: 67.19 % local_loss: 1.0863456\n",
      "test_accuracy: 18.4 % total_loss: 3.8388531\n",
      "<step: 1400>\n",
      "train_accuracy: 66.41 % local_loss: 0.87844253\n",
      "test_accuracy: 21.6 % total_loss: 3.8064663\n",
      "<step: 1500>\n",
      "train_accuracy: 71.88 % local_loss: 0.76793307\n",
      "test_accuracy: 19.07 % total_loss: 4.0527611\n",
      "<step: 1600>\n",
      "train_accuracy: 81.25 % local_loss: 0.5576815\n",
      "test_accuracy: 20.1 % total_loss: 4.1320367\n",
      "<step: 1700>\n",
      "train_accuracy: 71.88 % local_loss: 0.92776936\n",
      "test_accuracy: 19.95 % total_loss: 4.4656119\n",
      "<step: 1800>\n",
      "train_accuracy: 85.94 % local_loss: 0.43154043\n",
      "test_accuracy: 17.81 % total_loss: 4.5656276\n",
      "<step: 1900>\n",
      "train_accuracy: 78.12 % local_loss: 0.68131936\n",
      "test_accuracy: 19.25 % total_loss: 4.6385779\n",
      "<step: 2000>\n",
      "train_accuracy: 75 % local_loss: 0.7122038\n",
      "test_accuracy: 19.1 % total_loss: 4.7594757\n",
      "<step: 2100>\n",
      "train_accuracy: 92.19 % local_loss: 0.30600303\n",
      "test_accuracy: 19.18 % total_loss: 4.8165727\n",
      "<step: 2200>\n",
      "train_accuracy: 93.75 % local_loss: 0.20898482\n",
      "test_accuracy: 19.43 % total_loss: 5.0172157\n",
      "<step: 2300>\n",
      "train_accuracy: 92.19 % local_loss: 0.24246907\n",
      "test_accuracy: 20.17 % total_loss: 5.1097846\n",
      "<step: 2400>\n",
      "train_accuracy: 91.41 % local_loss: 0.26313645\n",
      "test_accuracy: 20.21 % total_loss: 5.2227507\n",
      "<step: 2500>\n",
      "train_accuracy: 91.41 % local_loss: 0.27884635\n",
      "test_accuracy: 18.77 % total_loss: 5.5283399\n",
      "<step: 2600>\n",
      "train_accuracy: 92.19 % local_loss: 0.24617952\n",
      "test_accuracy: 19.29 % total_loss: 5.434011\n",
      "<step: 2700>\n",
      "train_accuracy: 79.69 % local_loss: 0.50295794\n",
      "test_accuracy: 18.15 % total_loss: 5.8173018\n",
      "<step: 2800>\n",
      "train_accuracy: 94.53 % local_loss: 0.23623192\n",
      "test_accuracy: 21.02 % total_loss: 5.6306381\n",
      "<step: 2900>\n",
      "train_accuracy: 93.75 % local_loss: 0.20798132\n",
      "test_accuracy: 19.99 % total_loss: 5.783112\n",
      "------------------------------------\n",
      "training time:  1396.9996280999999  s\n",
      "test_accuracy: 17.22 % total_loss: 6.1247311\n"
     ]
    }
   ],
   "source": [
    "model = train() # RNN n_hidden=150, dropout=0.5, L2=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<step: 0>\n",
      "train_accuracy: 0.7812 % local_loss: 3.1063154\n",
      "test_accuracy: 6.809 % total_loss: 2.9494512\n",
      "<step: 100>\n",
      "train_accuracy: 19.53 % local_loss: 2.6463046\n",
      "test_accuracy: 16.64 % total_loss: 2.7068105\n",
      "<step: 200>\n",
      "train_accuracy: 21.88 % local_loss: 2.6135867\n",
      "test_accuracy: 16.97 % total_loss: 2.6648424\n",
      "<step: 300>\n",
      "train_accuracy: 24.22 % local_loss: 2.3458853\n",
      "test_accuracy: 19.84 % total_loss: 2.563504\n",
      "<step: 400>\n",
      "train_accuracy: 29.69 % local_loss: 2.2998233\n",
      "test_accuracy: 21.02 % total_loss: 2.5521312\n",
      "<step: 500>\n",
      "train_accuracy: 32.03 % local_loss: 2.1606925\n",
      "test_accuracy: 20.61 % total_loss: 2.6385729\n",
      "<step: 600>\n",
      "train_accuracy: 32.03 % local_loss: 2.1539917\n",
      "test_accuracy: 19.95 % total_loss: 2.6155984\n",
      "<step: 700>\n",
      "train_accuracy: 33.59 % local_loss: 2.0787683\n",
      "test_accuracy: 24 % total_loss: 2.538944\n",
      "<step: 800>\n",
      "train_accuracy: 35.16 % local_loss: 2.1280279\n",
      "test_accuracy: 21.35 % total_loss: 2.741565\n",
      "<step: 900>\n",
      "train_accuracy: 48.44 % local_loss: 1.6619174\n",
      "test_accuracy: 25.03 % total_loss: 2.5395069\n",
      "<step: 1000>\n",
      "train_accuracy: 46.88 % local_loss: 1.5747565\n",
      "test_accuracy: 24.14 % total_loss: 2.6785114\n",
      "<step: 1100>\n",
      "train_accuracy: 46.09 % local_loss: 1.6540643\n",
      "test_accuracy: 22.16 % total_loss: 2.786947\n",
      "<step: 1200>\n",
      "train_accuracy: 60.94 % local_loss: 1.2599809\n",
      "test_accuracy: 24.4 % total_loss: 2.8091905\n",
      "<step: 1300>\n",
      "train_accuracy: 39.06 % local_loss: 1.8434832\n",
      "test_accuracy: 24.48 % total_loss: 2.8767595\n",
      "<step: 1400>\n",
      "train_accuracy: 58.59 % local_loss: 1.183917\n",
      "test_accuracy: 24 % total_loss: 3.0207534\n",
      "<step: 1500>\n",
      "train_accuracy: 57.03 % local_loss: 1.2745284\n",
      "test_accuracy: 24.51 % total_loss: 3.0920417\n",
      "<step: 1600>\n",
      "train_accuracy: 57.03 % local_loss: 1.4238132\n",
      "test_accuracy: 20.46 % total_loss: 3.3180981\n",
      "<step: 1700>\n",
      "train_accuracy: 67.19 % local_loss: 1.0984863\n",
      "test_accuracy: 23.63 % total_loss: 3.127172\n",
      "<step: 1800>\n",
      "train_accuracy: 59.38 % local_loss: 1.2292273\n",
      "test_accuracy: 19.76 % total_loss: 3.3971705\n",
      "<step: 1900>\n",
      "train_accuracy: 60.16 % local_loss: 1.1885951\n",
      "test_accuracy: 22.01 % total_loss: 3.4632256\n",
      "<step: 2000>\n",
      "train_accuracy: 65.62 % local_loss: 1.0194571\n",
      "test_accuracy: 22.56 % total_loss: 3.4703341\n",
      "<step: 2100>\n",
      "train_accuracy: 77.34 % local_loss: 0.7356829\n",
      "test_accuracy: 23.11 % total_loss: 3.5057268\n",
      "<step: 2200>\n",
      "train_accuracy: 81.25 % local_loss: 0.64692271\n",
      "test_accuracy: 23.96 % total_loss: 3.6546805\n",
      "<step: 2300>\n",
      "train_accuracy: 69.53 % local_loss: 0.94539684\n",
      "test_accuracy: 21.38 % total_loss: 3.8495555\n",
      "<step: 2400>\n",
      "train_accuracy: 74.22 % local_loss: 0.84673864\n",
      "test_accuracy: 24.25 % total_loss: 3.8040297\n",
      "<step: 2500>\n",
      "train_accuracy: 59.38 % local_loss: 1.2827482\n",
      "test_accuracy: 21.35 % total_loss: 4.1492133\n",
      "<step: 2600>\n",
      "train_accuracy: 71.09 % local_loss: 0.92004317\n",
      "test_accuracy: 22.89 % total_loss: 3.9776402\n",
      "<step: 2700>\n",
      "train_accuracy: 79.69 % local_loss: 0.64824712\n",
      "test_accuracy: 22.89 % total_loss: 4.1004505\n",
      "<step: 2800>\n",
      "train_accuracy: 80.47 % local_loss: 0.58689165\n",
      "test_accuracy: 24.37 % total_loss: 4.1329303\n",
      "<step: 2900>\n",
      "train_accuracy: 77.34 % local_loss: 0.62449074\n",
      "test_accuracy: 24.59 % total_loss: 4.2055359\n",
      "------------------------------------\n",
      "training time:  1380.9990039  s\n",
      "test_accuracy: 22.34 % total_loss: 4.5134463\n"
     ]
    }
   ],
   "source": [
    "model = train() # RNN n_hidden=150, dropout=0.75, L2=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<step: 0>\n",
      "train_accuracy: 5.469 % local_loss: 2.9477136\n",
      "test_accuracy: 8.502 % total_loss: 2.9118285\n",
      "<step: 100>\n",
      "train_accuracy: 17.97 % local_loss: 2.5412292\n",
      "test_accuracy: 20.17 % total_loss: 2.5936091\n",
      "<step: 200>\n",
      "train_accuracy: 25.78 % local_loss: 2.3631718\n",
      "test_accuracy: 27.31 % total_loss: 2.3311367\n",
      "<step: 300>\n",
      "train_accuracy: 42.97 % local_loss: 1.6521778\n",
      "test_accuracy: 36.29 % total_loss: 1.976873\n",
      "<step: 400>\n",
      "train_accuracy: 62.5 % local_loss: 1.2153895\n",
      "test_accuracy: 45.27 % total_loss: 1.7492627\n",
      "<step: 500>\n",
      "train_accuracy: 63.28 % local_loss: 1.1227171\n",
      "test_accuracy: 42.99 % total_loss: 1.7962646\n",
      "<step: 600>\n",
      "train_accuracy: 69.53 % local_loss: 0.95380795\n",
      "test_accuracy: 48.77 % total_loss: 1.7715095\n",
      "<step: 700>\n",
      "train_accuracy: 78.91 % local_loss: 0.73090172\n",
      "test_accuracy: 50.02 % total_loss: 1.8223318\n",
      "<step: 800>\n",
      "train_accuracy: 83.59 % local_loss: 0.59417158\n",
      "test_accuracy: 49.36 % total_loss: 1.9133638\n",
      "<step: 900>\n",
      "train_accuracy: 89.84 % local_loss: 0.34373221\n",
      "test_accuracy: 48.73 % total_loss: 1.9946532\n",
      "<step: 1000>\n",
      "train_accuracy: 95.31 % local_loss: 0.21260661\n",
      "test_accuracy: 49.43 % total_loss: 2.0602853\n",
      "<step: 1100>\n",
      "train_accuracy: 91.41 % local_loss: 0.29543474\n",
      "test_accuracy: 51.42 % total_loss: 2.0866749\n",
      "<step: 1200>\n",
      "train_accuracy: 97.66 % local_loss: 0.11225015\n",
      "test_accuracy: 49.8 % total_loss: 2.3342869\n",
      "<step: 1300>\n",
      "train_accuracy: 91.41 % local_loss: 0.28414339\n",
      "test_accuracy: 51.67 % total_loss: 2.3257954\n",
      "<step: 1400>\n",
      "train_accuracy: 99.22 % local_loss: 0.059223808\n",
      "test_accuracy: 52.89 % total_loss: 2.4538624\n",
      "<step: 1500>\n",
      "train_accuracy: 98.44 % local_loss: 0.058633037\n",
      "test_accuracy: 52.04 % total_loss: 2.5233693\n",
      "<step: 1600>\n",
      "train_accuracy: 99.22 % local_loss: 0.044675592\n",
      "test_accuracy: 53.07 % total_loss: 2.5946891\n",
      "<step: 1700>\n",
      "train_accuracy: 100 % local_loss: 0.021379888\n",
      "test_accuracy: 52.37 % total_loss: 2.6648321\n",
      "<step: 1800>\n",
      "train_accuracy: 100 % local_loss: 0.050572883\n",
      "test_accuracy: 50.79 % total_loss: 2.7382929\n",
      "<step: 1900>\n",
      "train_accuracy: 99.22 % local_loss: 0.023511954\n",
      "test_accuracy: 52.67 % total_loss: 2.7003071\n",
      "<step: 2000>\n",
      "train_accuracy: 100 % local_loss: 0.015171636\n",
      "test_accuracy: 51.53 % total_loss: 2.7115347\n",
      "<step: 2100>\n",
      "train_accuracy: 100 % local_loss: 0.014583599\n",
      "test_accuracy: 53.15 % total_loss: 2.7231784\n",
      "<step: 2200>\n",
      "train_accuracy: 100 % local_loss: 0.011055954\n",
      "test_accuracy: 54.47 % total_loss: 2.7524927\n",
      "<step: 2300>\n",
      "train_accuracy: 100 % local_loss: 0.0056299753\n",
      "test_accuracy: 54.84 % total_loss: 2.7874632\n",
      "<step: 2400>\n",
      "train_accuracy: 100 % local_loss: 0.0062557459\n",
      "test_accuracy: 54.21 % total_loss: 2.9273841\n",
      "<step: 2500>\n",
      "train_accuracy: 100 % local_loss: 0.0046909116\n",
      "test_accuracy: 53.85 % total_loss: 2.989522\n",
      "<step: 2600>\n",
      "train_accuracy: 100 % local_loss: 0.010390352\n",
      "test_accuracy: 53.44 % total_loss: 3.0706909\n",
      "<step: 2700>\n",
      "train_accuracy: 100 % local_loss: 0.0023018569\n",
      "test_accuracy: 53.92 % total_loss: 3.0954866\n",
      "<step: 2800>\n",
      "train_accuracy: 100 % local_loss: 0.016612805\n",
      "test_accuracy: 53.51 % total_loss: 2.9467661\n",
      "<step: 2900>\n",
      "train_accuracy: 100 % local_loss: 0.015698507\n",
      "test_accuracy: 52.78 % total_loss: 3.0077479\n",
      "------------------------------------\n",
      "training time:  1509.2415279  s\n",
      "test_accuracy: 52.48 % total_loss: 2.9224513\n"
     ]
    }
   ],
   "source": [
    "model = train() # LSTM n_hidden=150, dropout=0.5, L2=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<step: 0>\n",
      "train_accuracy: 6.25 % local_loss: 2.9220266\n",
      "test_accuracy: 7.214 % total_loss: 2.9125187\n",
      "<step: 100>\n",
      "train_accuracy: 17.19 % local_loss: 2.639487\n",
      "test_accuracy: 16.75 % total_loss: 2.6832063\n",
      "<step: 200>\n",
      "train_accuracy: 17.97 % local_loss: 2.715559\n",
      "test_accuracy: 16.75 % total_loss: 2.6763699\n",
      "<step: 300>\n",
      "train_accuracy: 22.66 % local_loss: 2.5020874\n",
      "test_accuracy: 22.12 % total_loss: 2.5406444\n",
      "<step: 400>\n",
      "train_accuracy: 26.56 % local_loss: 2.4539399\n",
      "test_accuracy: 22.41 % total_loss: 2.5121427\n",
      "<step: 500>\n",
      "train_accuracy: 21.88 % local_loss: 2.4431083\n",
      "test_accuracy: 22.41 % total_loss: 2.4546094\n",
      "<step: 600>\n",
      "train_accuracy: 21.09 % local_loss: 2.4868965\n",
      "test_accuracy: 22.05 % total_loss: 2.4568908\n",
      "<step: 700>\n",
      "train_accuracy: 25.78 % local_loss: 2.3279834\n",
      "test_accuracy: 27.94 % total_loss: 2.233644\n",
      "<step: 800>\n",
      "train_accuracy: 31.25 % local_loss: 2.3453293\n",
      "test_accuracy: 29.37 % total_loss: 2.1344507\n",
      "<step: 900>\n",
      "train_accuracy: 26.56 % local_loss: 2.1394622\n",
      "test_accuracy: 28.74 % total_loss: 2.1359622\n",
      "<step: 1000>\n",
      "train_accuracy: 34.38 % local_loss: 2.0483053\n",
      "test_accuracy: 30.88 % total_loss: 2.0849597\n",
      "<step: 1100>\n",
      "train_accuracy: 26.56 % local_loss: 2.0920057\n",
      "test_accuracy: 30.07 % total_loss: 2.1108921\n",
      "<step: 1200>\n",
      "train_accuracy: 44.53 % local_loss: 1.8078284\n",
      "test_accuracy: 32.28 % total_loss: 2.0645635\n",
      "<step: 1300>\n",
      "train_accuracy: 28.91 % local_loss: 2.26247\n",
      "test_accuracy: 30.51 % total_loss: 2.071362\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-3f491419d6eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# LSTM n_hidden=150, dropout=0.5, L2=0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-bd652dd0d371>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_golden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_golden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-4326630b3643>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, sentences)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;31m# _, h = self.rnn(sentence, self.h0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    537\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 539\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[1;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[1;32m--> 522\u001b[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    523\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = train() # LSTM n_hidden=150, dropout=0.5, L2=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
